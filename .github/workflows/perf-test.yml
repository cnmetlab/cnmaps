# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: Python package

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build:
    name: Build test on (${{ matrix.python-version }}, ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ["3.9"]

    steps:
      - uses: actions/checkout@v3
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v3
        with:
          python-version: ${{ matrix.python-version }}
      - name: Set Python default encoding to utf-8 on Windows
        run: |
          echo "import sys; sys.stdout.reconfigure(encoding='utf-8')" > sitecustomize.py
        if: matrix.os == 'windows-latest'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install poetry
          poetry install
      - name: Lint with flake8
        run: |
          # stop the build if there are Python syntax errors or undefined names
          poetry run flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          poetry run flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      - name: Run tests and collect benchmark
        run: |
          poetry run pytest --verbose -p no:warnings --memray --benchmark-json output.json ./tests/test_perf.py
      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.14.0
        with:
          name: cnmaps Benchmark
          tool: "pytest"
          output-file-path: output.json
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/cnmetlab/cnmaps"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: true
          fail-on-alert: false
          benchmark-data-dir-path: "performance/"
          alert-comment-cc-users: "@clarmy"
      - name: Test with pytest
        run: |
          poetry run pytest --verbose -p no:warnings --cov ./tests/test_drawing.py ./tests/test_geo.py ./tests/test_map.py ./tests/test_issues.py
      - name: Upload coverage reports to Codecov
        run: |
          curl -Os https://uploader.codecov.io/latest/linux/codecov
          chmod +x codecov
          ./codecov -t ${{ secrets.CODECOV_TOKEN }}
